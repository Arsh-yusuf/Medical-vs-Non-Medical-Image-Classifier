{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_cyawFNNgaJ",
        "outputId": "783fcab6-9020-48bf-d9e1-cf14950df6c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set dataset path (update folder name as needed)\n",
        "data_dir = \"/content/drive/MyDrive/data\"\n"
      ],
      "metadata": {
        "id": "65avdSNvNtf2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset structure\n",
        "!ls $data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAOXREloOAw9",
        "outputId": "31810e7c-2eb6-4c41-fcd3-59591dcd6e1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision --quiet"
      ],
      "metadata": {
        "id": "a4oW3ZotOEFF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "olYbnv4OOI9I"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjkAx0yoOrUw",
        "outputId": "2c3ddc71-a5fd-4913-e579-7a8ea8ebdbd9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: DATA TRANSFORMS & LOADERS\n",
        "# ==============================\n",
        "batch_size = 32\n",
        "\n",
        "data_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "NMtfitn_Ov9a"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "image_datasets = {\n",
        "    x: datasets.ImageFolder(f\"{data_dir}/{x}\", data_transforms[x])\n",
        "    for x in ['train', 'val']\n",
        "}"
      ],
      "metadata": {
        "id": "1HtEgKsNO0Ol"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders\n",
        "dataloaders = {\n",
        "    x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    for x in ['train', 'val']\n",
        "}\n"
      ],
      "metadata": {
        "id": "h9CpFgNDO2m1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Train size:\", dataset_sizes['train'], \"Validation size:\", dataset_sizes['val'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qdX730cO-5u",
        "outputId": "f4d8a134-e4d4-492a-f25b-a73bc16d2cac"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['medical', 'non-medical']\n",
            "Train size: 3700 Validation size: 450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: MODEL - EfficientNet-B0\n",
        "# ==============================\n",
        "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Unfreeze last few layers for better feature learning\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.features[-3:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Replace classifier\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier[1].parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAnTXyUPPBdc",
        "outputId": "5a881d08-643a-44d6-e6a4-c5b40a8e255c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 133MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=3):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(\"-\" * 20)\n",
        "        for phase in ['train', 'val']:\n",
        "            model.train() if phase == 'train' else model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "nbEkicoqPFi_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: TRAIN MODEL\n",
        "# ==============================\n",
        "model = train_model(model, criterion, optimizer, num_epochs=3)"
      ],
      "metadata": {
        "id": "-v2ANXDWPK8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826318df-abb8-4367-abdd-a7235371f628"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "--------------------\n",
            "train Loss: 0.1464 Acc: 0.9643\n",
            "val Loss: 0.0582 Acc: 0.9889\n",
            "Epoch 2/3\n",
            "--------------------\n",
            "train Loss: 0.0493 Acc: 0.9892\n",
            "val Loss: 0.0361 Acc: 0.9978\n",
            "Epoch 3/3\n",
            "--------------------\n",
            "train Loss: 0.0424 Acc: 0.9886\n",
            "val Loss: 0.0269 Acc: 0.9978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/medical_vs_nonmedical_efficientnet_finetuned_1.pth\")\n",
        "print(\"Model saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j-7HsIfwkXV",
        "outputId": "6303d29d-2396-4a99-8748-be6ec96e0ef7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: PREDICTION FUNCTION\n",
        "# ==============================\n",
        "def predict_image(image_path):\n",
        "    model.eval()\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    transform = data_transforms['val']\n",
        "    img_t = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img_t)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        return class_names[pred]"
      ],
      "metadata": {
        "id": "s7-Ah5tpPUbz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = \"/content/drive/MyDrive/football.jpg\"\n",
        "print(predict_image(test_image_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXHOrTQ1dn2H",
        "outputId": "b0fc9741-743f-4e11-f3cf-62edd1464edb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "non-medical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uboXpzLifhD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce1b58e-1700-400f-8399-fdc44c7197a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk5Ipsj3idkx",
        "outputId": "a10881f6-249e-41ed-86c3-7f799571a89b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define model architecture\n",
        "model = models.efficientnet_b0(weights=None)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
        "\n",
        "# Load previously trained weights\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/medical_vs_nonmedical_efficientnet_finetuned.pth\", map_location=device))\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "t3MpnimSi36u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Transforms for augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/new_data\"\n",
        "\n",
        "# Load dataset (no validation split)\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "class_names = dataset.classes\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Dataset size:\", len(dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnSbuNNhjXQx",
        "outputId": "b42ce253-d0c9-4141-e4f3-e2ca1b126c93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['medical', 'non-medical']\n",
            "Dataset size: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.features[-3:].parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "metadata": {
        "id": "e-ky8ee_jtn2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)\n",
        "\n",
        "def fine_tune(model, dataloader, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels)\n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
        "    return model\n",
        "\n",
        "model = fine_tune(model, dataloader, epochs=3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prBmSBT3jxuX",
        "outputId": "da55e0c9-7ed2-4da7-a21f-b9e0b7bde8f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Loss: 0.6362, Acc: 0.7850\n",
            "Epoch 2/3 - Loss: 0.1043, Acc: 0.9700\n",
            "Epoch 3/3 - Loss: 0.0504, Acc: 0.9800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save updated model\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/medical_vs_nonmedical_efficientnet_finetuned_2.pth\")\n",
        "print(\"Fine-tuning complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B9-uL84j1vh",
        "outputId": "1ec12abb-c477-47e4-c965-565425da0f56"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# Same transforms as validation\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def predict_image(model, image_path):\n",
        "    model.eval()\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_t = test_transform(img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img_t)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "    return class_names[pred]\n",
        "\n",
        "print(predict_image(model, \"/content/drive/MyDrive/knee.jpeg\"))\n",
        "# print(predict_image(model, \"/content/drive/MyDrive/new_data/non-medical/car1.jpg\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg3Ee_kvkJaS",
        "outputId": "ea5f8861-64fc-4bf2-a3bb-ffef3cefc05b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "non-medical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KV6eJObakuw8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}